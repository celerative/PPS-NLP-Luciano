{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "**En este notebook se realizarán unas pruebas simples con el modelo Word2Vec de la libreria gensim y el Spooky Author's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luciano\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gensim \n",
    "import base64\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from collections import Counter\n",
    "from scipy.misc import imread\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "class LemmaCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo datos \n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gensim pre-processing: Divide las oraciones en tokens, convierte todo en lowercase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train= list(train.text.values)\n",
    "print(text_train[:3],\"\\n\")\n",
    "#Tokenizacion para cada oracion: Le paso un string, devuelve una lista de strings (tokens)\n",
    "for i in range(len(text_train)):\n",
    "   text_train[i]= gensim.utils.simple_preprocess(text_train[i])\n",
    "print(\"Matriz tokenizada de frases:\",text_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genero vocabulario y entreno el modelo\n",
    "**Parametros relevantes:**\n",
    "\n",
    " -Size corresponde al tamaño o dimensionalidad de vector de caracteristicas\n",
    " -Window: La cantidad de palabras correspondientes a la ventana de contexto\n",
    " -#min_count: palabras con frecuencia menor a este valor se ignoran\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luciano\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo = gensim.models.Word2Vec(\n",
    "        text_train,\n",
    "        sg=1,\n",
    "        size=125,\n",
    "        window=2,\n",
    "        min_count=5,\n",
    "        workers=8,\n",
    "         hs=1,\n",
    "        negative=10)\n",
    "modelo.train(text_train, total_examples=len(text_train), epochs=10)\n",
    "say_vector = modelo['say']  # get vector for word \n",
    "print(len(say_vector))\n",
    "\n",
    "#guardo modelo\n",
    "#word2vecsaved = 'word2vec_model.sav'\n",
    "#joblib.dump(modelo, word2vecsaved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una vez entrenado el modelo, hacemos Algunas pruebas ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.5323820025714207\n",
      "0.30694479761200993\n",
      "0.14496146023935153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('gentleman', 0.5479372143745422),\n",
       " ('poet', 0.5269320011138916),\n",
       " ('woman', 0.5269132852554321),\n",
       " ('painter', 0.5195095539093018),\n",
       " ('villain', 0.5179144144058228)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(modelo.wv.similarity('man','man'))\n",
    "print(modelo.wv.similarity('appeared','seemed'))\n",
    "print(modelo.wv.similarity('cat','dog'))\n",
    "print(modelo.wv.similarity('god','sun'))\n",
    "modelo.wv.most_similar(positive='man',topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.wv.doesnt_match(\"big ugly monster cat\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8465, 125)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.1866464 , -0.07258397, -0.02347344, ...,  0.02865851,\n",
       "         0.11161629, -0.03977592],\n",
       "       [-0.3784538 ,  0.08856384, -0.14281073, ...,  0.2070911 ,\n",
       "         0.24291275, -0.18555847],\n",
       "       [-0.09305538,  0.0163871 ,  0.08069561, ...,  0.04641417,\n",
       "         0.07374206,  0.1390312 ],\n",
       "       ...,\n",
       "       [ 0.10724758,  0.08260011,  0.2057975 , ..., -0.16666321,\n",
       "        -0.09043068, -0.04211831],\n",
       "       [-0.21171324, -0.38264614,  0.07061048, ..., -0.54591143,\n",
       "         0.14919266,  0.03981583],\n",
       "       [ 0.3579407 ,  0.11960463,  0.14988564, ...,  0.2265596 ,\n",
       "        -0.04013533,  0.00141258]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_wordmatrix=modelo.wv.vectors\n",
    "print(w2v_wordmatrix.shape)\n",
    "w2v_wordmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
